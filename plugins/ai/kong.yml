_format_version: "3.0"
_transform: true

services:
  - name: chat-service
    host: httpbin.org
    port: 80
    protocol: http
    routes:
      - name: llm-route
        paths:
          - /chat
        strip_path: true

plugins:
  - name: opentelemetry
    config:
      traces_endpoint: http://otel-collector:4318/v1/traces
      logs_endpoint: http://otel-collector:4318/v1/logs
      resource_attributes:
        service.name: kong-otel-plugin
  - name: http-log
    config:
      http_endpoint: http://fluent-bit:2020
      custom_fields_by_lua:
        traceid: |
          local h = kong.request.get_header('traceparent')
          return h:match("%-([a-f0-9]+)%-[a-f0-9]+%-")
        spanid: |
          local h = kong.request.get_header('traceparent')
          return h:match("%-[a-f0-9]+%-([a-f0-9]+)%-")
  - name: prometheus
    config:
      per_consumer: true
      status_code_metrics: true
      ai_metrics: true
      latency_metrics: true
      bandwidth_metrics: true
      upstream_health_metrics: true
      wasm_metrics: true
  - name: ai-proxy
    service: chat-service
    config:
      route_type: llm/v1/chat
      auth:
        header_name: Authorization
        header_value: Bearer ${{ env "DECK_OPENAI_API_KEY" }}
      model:
        provider: openai
        name: gpt-4o-mini
        options:
          input_cost: 0.15
          output_cost: 0.6
          max_tokens: 1024
          temperature: 0
          top_k: 100
          top_p: 0
  # - name: ai-proxy-advanced
  #   service: chat-service
  #   config:
  #     balancer:
  #       algorithm: lowest-usage
  #       latency_strategy: tpot
  #     targets:
  #       - model:
  #           provider: openai
  #           name: gpt-4o-mini
  #           options:
  #             input_cost: 0.15
  #             output_cost: 0.6
  #             max_tokens: 1024
  #             temperature: 0
  #             top_k: 100
  #             top_p: 0
  #         route_type: llm/v1/chat
  #         auth:
  #           header_name: Authorization
  #           header_value: Bearer ${{ env "DECK_OPENAI_API_KEY" }}
  #         logging:
  #           log_payloads: true
  #           log_statistics: true
  #       - model:
  #           provider: openai
  #           name: gpt-4.1-mini
  #           options:
  #             input_cost: 0.4
  #             output_cost: 1.6
  #             max_tokens: 1024
  #             temperature: 0
  #             top_k: 100
  #             top_p: 0
  #         route_type: llm/v1/chat
  #         auth:
  #           header_name: Authorization
  #           header_value: Bearer ${{ env "DECK_OPENAI_API_KEY" }}
  #         logging:
  #           log_payloads: true
  #           log_statistics: true
  #       - model:
  #           provider: openai
  #           name: gpt-4.1-nano
  #           options:
  #             input_cost: 0.1
  #             output_cost: 0.4
  #             max_tokens: 1024
  #             temperature: 0
  #             top_k: 100
  #             top_p: 0
  #         route_type: llm/v1/chat
  #         auth:
  #           header_name: Authorization
  #           header_value: Bearer ${{ env "DECK_OPENAI_API_KEY" }}
  #         logging:
  #           log_payloads: true
  #           log_statistics: true
  - name: ai-prompt-decorator
    service: chat-service
    config:
      prompts:
        prepend:
          - role: system
            content: あなたは賢いゴリラです。質問に対して必ずゴリラになりきって「ウホ」や「ゴリ」などの口調で回答してください。
  - name: ai-rag-injector
    service: chat-service
    config:
      embeddings:
        auth:
          header_name: Authorization
          header_value: Bearer ${{ env "DECK_OPENAI_API_KEY" }}
        model:
          provider: openai
          name: text-embedding-3-small
      vectordb:
        strategy: redis
        redis:
          host: redis
          port: 6379
        distance_metric: cosine
        dimensions: 1536
      vectordb_namespace: kong_rag_injector
  - name: ai-semantic-cache
    service: chat-service
    config:
      embeddings:
        auth:
          header_name: Authorization
          header_value: Bearer ${{ env "DECK_OPENAI_API_KEY" }}
        model:
          provider: openai
          name: text-embedding-3-small
      vectordb:
        dimensions: 1536
        distance_metric: cosine
        strategy: redis
        threshold: 0.1
        redis:
          host: redis
          port: 6379
  # - name: ai-prompt-guard
  #   service: chat-service
  #   config:
  #     allow_patterns:
  #       - ".*Kong.*"
  #     deny_patterns:
  #       - ".*コング.*"
  - name: ai-semantic-prompt-guard
    service: chat-service
    config:
      embeddings:
        auth:
          header_name: Authorization
          header_value: Bearer ${{ env "DECK_OPENAI_API_KEY" }}
        model:
          provider: openai
          name: text-embedding-3-small
      search:
        threshold: 0.5
      vectordb:
        strategy: redis
        distance_metric: cosine
        threshold: 0.7
        dimensions: 1536
        redis:
          host: redis
          port: 6379
      rules:
        allow_prompts:
          - Kong Gatewayに関する質問
          - ゴリラに関する質問
          - コングロケットに関する質問
        deny_prompts:
          - 政治に関する質問
          - 野球に関する質問
